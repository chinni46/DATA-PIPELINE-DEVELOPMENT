# DATA-PIPELINE-DEVELOPMENT
# Task 1 (Pro Level): Data Pipeline for Data Preprocessing, Transformation, and Loading

**Internship**: CODTECH Data Science

---

## ğŸ§  Objective
To implement a professional-grade ETL pipeline using Python on the Iris dataset with structured code, exploratory data analysis, transformation logic, visualization, and validation.

---

## ğŸ› ï¸ Tools Used
- Python 3.x
- pandas, numpy, seaborn, matplotlib
- scikit-learn (LabelEncoder, StandardScaler, Pipeline)

---

## ğŸ“Š Features
- Modular code with functions
- Data visualization using seaborn
- Label encoding & scaling
- Automated checks/assertions
- CSV export of processed data

---

## ğŸ—‚ï¸ Files
- `Task1_DataPipeline_Pro.ipynb` â€“ Complete Jupyter notebook
- `processed_iris_data.csv` â€“ Final transformed dataset
- `README_Pro.md` â€“ This documentation

---

## â–¶ï¸ How to Run
```bash
pip install pandas numpy seaborn matplotlib scikit-learn
```

Then open the notebook and run all cells.

---

## ğŸ“ˆ Sample Output
Includes visual pair plots of scaled features by class (`target`).

---

**Submitted for Completion Certificate**  
**Internship â€“ CODTECH | Task 1**
