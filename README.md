# DATA-PIPELINE-DEVELOPMENT
# Task 1 (Pro Level): Data Pipeline for Data Preprocessing, Transformation, and Loading

**Internship**: CODTECH Data Science

---

## 🧠 Objective
To implement a professional-grade ETL pipeline using Python on the Iris dataset with structured code, exploratory data analysis, transformation logic, visualization, and validation.

---

## 🛠️ Tools Used
- Python 3.x
- pandas, numpy, seaborn, matplotlib
- scikit-learn (LabelEncoder, StandardScaler, Pipeline)

---

## 📊 Features
- Modular code with functions
- Data visualization using seaborn
- Label encoding & scaling
- Automated checks/assertions
- CSV export of processed data

---

## 🗂️ Files
- `Task1_DataPipeline_Pro.ipynb` – Complete Jupyter notebook
- `processed_iris_data.csv` – Final transformed dataset
- `README_Pro.md` – This documentation

---

## ▶️ How to Run
```bash
pip install pandas numpy seaborn matplotlib scikit-learn
```

Then open the notebook and run all cells.

---

## 📈 Sample Output
Includes visual pair plots of scaled features by class (`target`).

---

**Submitted for Completion Certificate**  
**Internship – CODTECH | Task 1**
